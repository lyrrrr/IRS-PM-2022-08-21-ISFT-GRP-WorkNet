{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SxzJ6SmuXkf4","executionInfo":{"status":"ok","timestamp":1666932437298,"user_tz":-480,"elapsed":24296,"user":{"displayName":"Qi Li","userId":"16904504519531243661"}},"outputId":"7ebc4da4-a32d-421c-8e77-18c22d5f618e"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","source":["###### change current path\n","import os\n","path = \"/content/gdrive/MyDrive/NUS_IRS_Project/\"\n","os.chdir(path)\n","!ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UUmHeHeYXlF-","executionInfo":{"status":"ok","timestamp":1666932545281,"user_tz":-480,"elapsed":369,"user":{"displayName":"Qi Li","userId":"16904504519531243661"}},"outputId":"2a6bf771-ffd0-4092-b9d8-026429d0c7df"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["data  data_gathering  matching\tModelling  models  webapp_model.zip\n"]}]},{"cell_type":"markdown","metadata":{"id":"mPefKIVqXdPJ"},"source":["# Job - Pre-processing and Modelling Iteration final"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"l_87eAr6XdPN","executionInfo":{"status":"ok","timestamp":1666932548906,"user_tz":-480,"elapsed":306,"user":{"displayName":"Qi Li","userId":"16904504519531243661"}}},"outputs":[],"source":["# libraries import\n","import numpy as np\n","import pandas as pd\n","import json\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","import re\n","import datetime\n","from datetime import date\n","from time import strptime\n","import operator\n"]},{"cell_type":"markdown","metadata":{"id":"zmhnoHv2XdPP"},"source":["######################################################################################\n","\n","# Working on Job description Data\n","######################################################################################   "]},{"cell_type":"code","execution_count":4,"metadata":{"id":"WreGWNsoXdPP","executionInfo":{"status":"ok","timestamp":1666932553003,"user_tz":-480,"elapsed":1518,"user":{"displayName":"Qi Li","userId":"16904504519531243661"}}},"outputs":[],"source":["# reading my sorted job csv\n","job = pd.read_csv('data/EDA_job.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YKOmjeM0XdPQ","executionInfo":{"status":"ok","timestamp":1666504014049,"user_tz":-480,"elapsed":385,"user":{"displayName":"Qi Li","userId":"16904504519531243661"}},"outputId":"6d57176b-9e84-4a20-93c1-47c8b5d75571"},"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 21996 entries, 0 to 21995\n","Data columns (total 10 columns):\n"," #   Column               Non-Null Count  Dtype  \n","---  ------               --------------  -----  \n"," 0   company              21996 non-null  object \n"," 1   education            20004 non-null  object \n"," 2   experience           21996 non-null  object \n"," 3   industry             21996 non-null  object \n"," 4   jobdescription       21996 non-null  object \n"," 5   joblocation_address  21499 non-null  object \n"," 6   jobtitle             21996 non-null  object \n"," 7   numberofpositions    4464 non-null   float64\n"," 8   postdate             21977 non-null  object \n"," 9   skills               21996 non-null  object \n","dtypes: float64(1), object(9)\n","memory usage: 1.7+ MB\n"]}],"source":["job.info()"]},{"cell_type":"markdown","metadata":{"id":"swK2yIeZXdPR"},"source":["###########################################################################################################################\n","# Understanding Job_description column (using NLP)\n","###########################################################################################################################\n"]},{"cell_type":"markdown","metadata":{"id":"z_fzNZi0XdPR"},"source":["# 1. NLP - NLTK application to understand most used words"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"UFAiy_DJXdPS","outputId":"fc5c559a-95ec-4d45-86bb-bc0ff87f2d4d","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1666932559972,"user_tz":-480,"elapsed":2105,"user":{"displayName":"Qi Li","userId":"16904504519531243661"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]}],"source":["#Import all the dependencies\n","import nltk\n","nltk.download('wordnet')\n","from nltk.stem import WordNetLemmatizer\n","wordnet_lemmatizer = WordNetLemmatizer()\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize \n","nltk.download('stopwords')\n","\n","import string\n","stopwords = set(stopwords.words(\"english\"))\n","import gensim\n","from gensim.test.utils import common_texts\n","from gensim.models.doc2vec import Doc2Vec, TaggedDocument"]},{"cell_type":"code","source":["from nltk import word_tokenize, pos_tag\n","from nltk.corpus import wordnet\n","from nltk.stem import WordNetLemmatizer\n","\n","# 获取单词的词性\n","def get_wordnet_pos(tag):\n","    if tag.startswith('J'):\n","        return wordnet.ADJ\n","    elif tag.startswith('V'):\n","        return wordnet.VERB\n","    elif tag.startswith('N'):\n","        return wordnet.NOUN\n","    elif tag.startswith('R'):\n","        return wordnet.ADV\n","    else:\n","        return None"],"metadata":{"id":"fj6FjDLyiCNK"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dwn5SxLiXdPT"},"outputs":[],"source":["# defining tokenizer \n","def my_tokenizer(text):\n","    # 1. split at whitespace\n","    text = text.split(' ')\n","    \n","    #2. lowercase\n","    text = [word.lower() for word in text]\n","    \n","    #3. Remove puncutation\n","    #table to replace puncuation\n","    punc_table = str.maketrans('','',string.punctuation)\n","    \n","    #call translate()\n","    text = [word.translate(punc_table) for word in text]\n","    \n","    #4. remove stopwords\n","    text = [word for word in text if word not in stopwords]\n","    \n","    #5. lemmmatize\n","    tagged_sent = pos_tag(text)     # 获取单词词性\n","\n","    wnl = WordNetLemmatizer()\n","    lemmas_sent = []\n","    for tag in tagged_sent:\n","      wordnet_pos = get_wordnet_pos(tag[1]) or wordnet.NOUN\n","      lemmas_sent.append(wnl.lemmatize(tag[0], pos=wordnet_pos)) # 词形还原\n","\n","    # lemmatizer = WordNetLemmatizer()\n","    # text = [lemmatizer.lemmatize(word, pos='v') for word in text]\n","    # text = [lemmatizer.lemmatize(word, pos='n') for word in text]\n","    # text = [lemmatizer.lemmatize(word, pos='a') for word in text]\n","    \n","    #6. remove empty strings\n","    text = [word for word in lemmas_sent if word !='']\n","    \n","    return text "]},{"cell_type":"markdown","metadata":{"id":"m5sCYn8SXdPU"},"source":["# 2. NLP - TF-IDF application to get a list of all tokens \n","-- This helped to gather what words needed to be in stop-words list"]},{"cell_type":"code","source":["job['jobdescription'][0:5]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HIr2oF-M71H5","executionInfo":{"status":"ok","timestamp":1666932774703,"user_tz":-480,"elapsed":353,"user":{"displayName":"Qi Li","userId":"16904504519531243661"}},"outputId":"c0cde3f8-167d-4a45-95e0-e7b84701e393"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0    Job Description   Send me Jobs like this Quali...\n","1    Job Description   Send me Jobs like this Quali...\n","2    Job Description   Send me Jobs like this - as ...\n","3    Job Description   Send me Jobs like this - Inv...\n","4    Job Description   Send me Jobs like this Pleas...\n","Name: jobdescription, dtype: object"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["job['jobdescription'] = job['jobdescription'].map(lambda x: x.strip().strip('Job Description').strip())"],"metadata":{"id":"NBLCitL0j3LG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["job['jobdescription'] = job['jobdescription'].map(lambda x: x.strip('Send me Jobs like this').strip())"],"metadata":{"id":"wDn-aqCRlIFF"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L5QqfYN1XdPU","outputId":"d304271c-796d-483c-efe2-db1614d0ee4e","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1666504130658,"user_tz":-480,"elapsed":559,"user":{"displayName":"Qi Li","userId":"16904504519531243661"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0    Qualifications: - == > 10th To Graduation & An...\n","1    Qualifications: - == > 10th To Graduation & An...\n","2    - as a developer in providing application desi...\n","3    - Involved with all stages of indirect taxatio...\n","4    Please share your Resume on : regina.mary@spir...\n","Name: jobdescription, dtype: object"]},"metadata":{},"execution_count":11}],"source":["# job['jobdescription'] = job.jobdescription.str[40:]\n","job['jobdescription'][0:5]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qnDjWx4rXdPV","outputId":"927b2524-4d55-4ece-f815-d11d47c3d17a","colab":{"base_uri":"https://localhost:8080/","height":306},"executionInfo":{"status":"ok","timestamp":1666504133509,"user_tz":-480,"elapsed":513,"user":{"displayName":"Qi Li","userId":"16904504519531243661"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  \n"]},{"output_type":"execute_result","data":{"text/plain":["                                   jobtitle  \\\n","0  walkin data entry operator (night shift)   \n","1        work based onhome based part time.   \n","2                    pl/sql developer - sql   \n","3    manager/ad/partner - indirect tax - ca   \n","4           java technical lead (6-8 yrs) -   \n","\n","                                      company  \\\n","0                            MM Media Pvt Ltd   \n","1                          find live infotech   \n","2         Softtech Career Infosystem Pvt. Ltd   \n","3                      Onboard HRServices LLP   \n","4  Spire Technologies and Solutions Pvt. Ltd.   \n","\n","                                            jd_combo  \n","0  walkin data entry operator (night shift) Quali...  \n","1  work based onhome based part time. Qualificati...  \n","2  pl/sql developer - sql - as a developer in pro...  \n","3  manager/ad/partner - indirect tax - ca - Invol...  \n","4  java technical lead (6-8 yrs) - Please share y...  "],"text/html":["\n","  <div id=\"df-2b81a264-e7be-4915-b0a1-91d6ebd30c67\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>jobtitle</th>\n","      <th>company</th>\n","      <th>jd_combo</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>walkin data entry operator (night shift)</td>\n","      <td>MM Media Pvt Ltd</td>\n","      <td>walkin data entry operator (night shift) Quali...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>work based onhome based part time.</td>\n","      <td>find live infotech</td>\n","      <td>work based onhome based part time. Qualificati...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>pl/sql developer - sql</td>\n","      <td>Softtech Career Infosystem Pvt. Ltd</td>\n","      <td>pl/sql developer - sql - as a developer in pro...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>manager/ad/partner - indirect tax - ca</td>\n","      <td>Onboard HRServices LLP</td>\n","      <td>manager/ad/partner - indirect tax - ca - Invol...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>java technical lead (6-8 yrs) -</td>\n","      <td>Spire Technologies and Solutions Pvt. Ltd.</td>\n","      <td>java technical lead (6-8 yrs) - Please share y...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2b81a264-e7be-4915-b0a1-91d6ebd30c67')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-2b81a264-e7be-4915-b0a1-91d6ebd30c67 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-2b81a264-e7be-4915-b0a1-91d6ebd30c67');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":12}],"source":["df_job_descriptions = job[['jobtitle','company']]\n","df_job_descriptions['jd_combo'] = job['jobtitle']+\" \" +job['jobdescription']+\" \"+job['skills']+\" \"+job['industry']\n","df_job_descriptions.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"KVNz7TH7XdPW","outputId":"05b39a26-5407-4bc7-c03c-7d2246303297","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1666504195072,"user_tz":-480,"elapsed":13538,"user":{"displayName":"Qi Li","userId":"16904504519531243661"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ëœ'] not in stop_words.\n","  % sorted(inconsistent)\n"]},{"output_type":"stream","name":"stdout","text":["(21996, 58619)\n","(21996, 3)\n"]}],"source":["from sklearn.feature_extraction.text import TfidfVectorizer\n","stopwords = nltk.corpus.stopwords.words('english')\n","stopwords.append('ã¯æ’ëœ')\n","#Transforms words to TFIDF\n","vectorizer = TfidfVectorizer(stop_words = stopwords)\n","\n","index = 0\n","keys = {}\n","\n","for jd in df_job_descriptions.itertuples() :\n","    key = jd[0]\n","    keys[key] = index\n","    index += 1\n","    \n","#Transforms words to TFIDF\n","vectorizer = TfidfVectorizer(stop_words = stopwords)\n","\n","#Fit the vectorizer to the data\n","vectorizer.fit(df_job_descriptions['jd_combo'].fillna(''))\n","\n","#Transform the data\n","tfidf_scores = vectorizer.transform(df_job_descriptions['jd_combo'].fillna(''))\n","\n","print(tfidf_scores.shape)\n","print(df_job_descriptions.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uyVklbfTXdPW","outputId":"98d4cf7f-cbfc-478e-9570-c679bdf0ecd3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1666504542833,"user_tz":-480,"elapsed":340,"user":{"displayName":"Qi Li","userId":"16904504519531243661"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["scipy.sparse.csr.csr_matrix"]},"metadata":{},"execution_count":14}],"source":["type(tfidf_scores)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4UefaoAFXdPX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1666504550828,"user_tz":-480,"elapsed":6630,"user":{"displayName":"Qi Li","userId":"16904504519531243661"}},"outputId":"fc37c398-2405-4404-86cb-20b8de4f39f0"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n","  warnings.warn(msg, category=FutureWarning)\n"]}],"source":["test = pd.DataFrame(tfidf_scores.toarray(), columns = vectorizer.get_feature_names())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6-qM4Y6-XdPY","outputId":"c114a7cf-4f4a-4885-dd38-1525d42d067c","colab":{"base_uri":"https://localhost:8080/","height":233},"executionInfo":{"status":"ok","timestamp":1666504603815,"user_tz":-480,"elapsed":369,"user":{"displayName":"Qi Li","userId":"16904504519531243661"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["    00       000  0000  00000  0000gmt  0001pt  00029  00034  000402  00053  \\\n","0  0.0  0.059693   0.0    0.0      0.0     0.0    0.0    0.0     0.0    0.0   \n","1  0.0  0.070372   0.0    0.0      0.0     0.0    0.0    0.0     0.0    0.0   \n","2  0.0  0.000000   0.0    0.0      0.0     0.0    0.0    0.0     0.0    0.0   \n","3  0.0  0.000000   0.0    0.0      0.0     0.0    0.0    0.0     0.0    0.0   \n","4  0.0  0.000000   0.0    0.0      0.0     0.0    0.0    0.0     0.0    0.0   \n","\n","   ...   ïƒ  ïƒ¼  ïƒž  œ100  œmost  œrecognition  œto   šâ   šã   žâ  \n","0  ...  0.0  0.0  0.0   0.0    0.0           0.0  0.0  0.0  0.0  0.0  \n","1  ...  0.0  0.0  0.0   0.0    0.0           0.0  0.0  0.0  0.0  0.0  \n","2  ...  0.0  0.0  0.0   0.0    0.0           0.0  0.0  0.0  0.0  0.0  \n","3  ...  0.0  0.0  0.0   0.0    0.0           0.0  0.0  0.0  0.0  0.0  \n","4  ...  0.0  0.0  0.0   0.0    0.0           0.0  0.0  0.0  0.0  0.0  \n","\n","[5 rows x 58619 columns]"],"text/html":["\n","  <div id=\"df-522fa950-499f-4e05-8a35-0eacaea5cadd\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>00</th>\n","      <th>000</th>\n","      <th>0000</th>\n","      <th>00000</th>\n","      <th>0000gmt</th>\n","      <th>0001pt</th>\n","      <th>00029</th>\n","      <th>00034</th>\n","      <th>000402</th>\n","      <th>00053</th>\n","      <th>...</th>\n","      <th>ïƒ</th>\n","      <th>ïƒ¼</th>\n","      <th>ïƒž</th>\n","      <th>œ100</th>\n","      <th>œmost</th>\n","      <th>œrecognition</th>\n","      <th>œto</th>\n","      <th>šâ</th>\n","      <th>šã</th>\n","      <th>žâ</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.0</td>\n","      <td>0.059693</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.0</td>\n","      <td>0.070372</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 58619 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-522fa950-499f-4e05-8a35-0eacaea5cadd')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-522fa950-499f-4e05-8a35-0eacaea5cadd button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-522fa950-499f-4e05-8a35-0eacaea5cadd');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":16}],"source":["test.head()"]},{"cell_type":"markdown","metadata":{"id":"dElB267XXdPZ"},"source":["As count vectorizer and Tf-Idf are only exploding my column numbers. It might not be wise to proceed with any of these. Moveover, I need to compare job description with Resume, that may not with fair comparison. So I will use these results so far for customizing stop word list. And will later use Doc2Vec to train my model."]},{"cell_type":"markdown","metadata":{"id":"ISFSAXN2XdPZ"},"source":["# Creating my Stopword list \n","\n","### As seen there are so many unwanted tokens like numbers,ïƒ¼ etc , I need to add them in \"stop words\" list to train model "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Qm4XhlVsXdPa"},"outputs":[],"source":["############## use the result column of Tf-ldf to generate stop words\n","#getting list of all tokens\n","word_list = test.columns.tolist()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0HNx0LbZXdPa"},"outputs":[],"source":["##Getting a list of unwanted words as s_words and adding to stopwords\n","s_words =[]\n","for word in word_list:\n","    #print(word)\n","    if re.search(\"^\\W|^\\d\",word):\n","        s_words.append(word)\n","        "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GgvozG30XdPb"},"outputs":[],"source":["s_words.append('')        \n","from nltk.corpus import stopwords\n","stopword_set = set(stopwords.words('english'))\n","stopword_set = list(stopword_set)\n","stopword_set.extend(s_words)"]},{"cell_type":"markdown","metadata":{"id":"lZ2QgKWhXdPb"},"source":["# Collecting all text data for DOC2VEC modelling\n","In final iteration, I only used job title and job description for creating text combo document and got my 20-D vectors. This time I trained my model on 200 epochs. \n","\n","As count vectorizer and Tf-Idf are only exploding my column numbers. It might not be wise to proceed with any of these. Moveover, I need to compare job description with Resume, that may not with fair comparison. \n","\n","Definately Doc2Vec is the smart choice to make to proceed with matching. Because Doc2Vec has ability to read document as a whole rather than working on each single word. It has a feature to provide n-Dimentional vectors. \n","\n","So I am going to use same concept to get my vectors. Then I ll use those vectors to match it against any given resume. \n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j3vVInltXdPb","outputId":"b043799f-c6e3-497d-aebb-f22b7255325e","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1666504616053,"user_tz":-480,"elapsed":8,"user":{"displayName":"Qi Li","userId":"16904504519531243661"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                   jobtitle  \\\n","0  walkin data entry operator (night shift)   \n","1        work based onhome based part time.   \n","2                    pl/sql developer - sql   \n","3    manager/ad/partner - indirect tax - ca   \n","4           java technical lead (6-8 yrs) -   \n","\n","                                      company  \\\n","0                            MM Media Pvt Ltd   \n","1                          find live infotech   \n","2         Softtech Career Infosystem Pvt. Ltd   \n","3                      Onboard HRServices LLP   \n","4  Spire Technologies and Solutions Pvt. Ltd.   \n","\n","                                            jd_combo  \n","0  walkin data entry operator (night shift) Quali...  \n","1  work based onhome based part time. Qualificati...  \n","2  pl/sql developer - sql - as a developer in pro...  \n","3  manager/ad/partner - indirect tax - ca - Invol...  \n","4  java technical lead (6-8 yrs) - Please share y...  "],"text/html":["\n","  <div id=\"df-3b8a9276-7ac0-4d24-ad97-d2eec7881e97\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>jobtitle</th>\n","      <th>company</th>\n","      <th>jd_combo</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>walkin data entry operator (night shift)</td>\n","      <td>MM Media Pvt Ltd</td>\n","      <td>walkin data entry operator (night shift) Quali...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>work based onhome based part time.</td>\n","      <td>find live infotech</td>\n","      <td>work based onhome based part time. Qualificati...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>pl/sql developer - sql</td>\n","      <td>Softtech Career Infosystem Pvt. Ltd</td>\n","      <td>pl/sql developer - sql - as a developer in pro...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>manager/ad/partner - indirect tax - ca</td>\n","      <td>Onboard HRServices LLP</td>\n","      <td>manager/ad/partner - indirect tax - ca - Invol...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>java technical lead (6-8 yrs) -</td>\n","      <td>Spire Technologies and Solutions Pvt. Ltd.</td>\n","      <td>java technical lead (6-8 yrs) - Please share y...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3b8a9276-7ac0-4d24-ad97-d2eec7881e97')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-3b8a9276-7ac0-4d24-ad97-d2eec7881e97 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-3b8a9276-7ac0-4d24-ad97-d2eec7881e97');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":20}],"source":["df_job_descriptions.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JnIJPqXtXdPc","outputId":"7f740eb5-3ec0-4845-ba2a-a121e1eea62b","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1666504618505,"user_tz":-480,"elapsed":322,"user":{"displayName":"Qi Li","userId":"16904504519531243661"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0    walkin data entry operator (night shift) Quali...\n","1    work based onhome based part time. Qualificati...\n","2    pl/sql developer - sql - as a developer in pro...\n","3    manager/ad/partner - indirect tax - ca - Invol...\n","4    java technical lead (6-8 yrs) - Please share y...\n","5    walk in - as400 developer - pfsweb global serv...\n","6    php developer xperience/strong knowledge in PH...\n","7    member technical staff-wire harness/cable harn...\n","8    team leader Independent handling of entire pro...\n","9    german translator Overall Purpose of Job and R...\n","Name: jd_combo, dtype: object"]},"metadata":{},"execution_count":21}],"source":["docs = df_job_descriptions['jd_combo']\n","docs_sample = docs.head(10)\n","docs_sample"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AvjCHldaXdPc"},"outputs":[],"source":["#pre-processing with custom stop word list\n","def preprocess(text):\n","    stop_words = stopword_set\n","    #0. split words by whitespace\n","    text = text.split()\n","    \n","    # 1. lower case\n","    text = [word.lower() for word in text]\n","    \n","    # 2. remove punctuations\n","    punc_table = str.maketrans('','',string.punctuation)\n","    text = [word.translate(punc_table) for word in text]\n","    \n","    # 3. remove stop words\n","    text = [word for word in text if word not in stop_words]\n","    \n","    return text"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CJx-MlW9XdPd"},"outputs":[],"source":["# calling my pre-process to tokenize \n","tokenized_doc = []\n","doc = df_job_descriptions['jd_combo']\n","#doc = docs_sample\n","for d in doc:\n","    tokenized_doc.append(preprocess(d))\n","#tokenized_doc"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tA_VHiWOXdPd"},"outputs":[],"source":["# Convert tokenized document into gensim formated tagged data\n","tagged_data = [TaggedDocument(d, [i]) for i, d in enumerate(tokenized_doc)]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rhIjuragXdPd","outputId":"22bb8e19-f567-4173-e19c-376aac363712","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1666456968605,"user_tz":-480,"elapsed":352,"user":{"displayName":"Qi Li","userId":"16904504519531243661"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["21996"]},"metadata":{},"execution_count":25}],"source":["num_doc = len(tagged_data)\n","num_doc"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lPn3aTokXdPd"},"outputs":[],"source":["#settings to show epoch progress\n","from gensim.test.utils import get_tmpfile\n","from gensim.models.callbacks import CallbackAny2Vec\n","\n","class EpochSaver(CallbackAny2Vec):\n","\n","    def __init__(self, path_prefix):\n","        self.path_prefix = path_prefix\n","        self.epoch = 0\n","\n","    def on_epoch_end(self, model):\n","        output_path = get_tmpfile('{}_epoch{}.model'.format(self.path_prefix, self.epoch))\n","        model.save(output_path)\n","        self.epoch += 1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CXIN-4zRXdPe"},"outputs":[],"source":["#settings to show epoch progress\n","class EpochLogger(CallbackAny2Vec):\n","    \n","    def __init__(self):\n","        self.epoch = 0\n","        \n","    def on_epoch_begin(self, model):\n","        print(\"Epoch #{} start\".format(self.epoch))\n","\n","    def on_epoch_end(self, model):\n","        print(\"Epoch #{} end\".format(self.epoch))\n","        self.epoch += 1"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"UQBL89gpXdPe","outputId":"c96ce3c7-dd52-4860-8c36-82674ccb682c","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1666459108257,"user_tz":-480,"elapsed":2029054,"user":{"displayName":"Qi Li","userId":"16904504519531243661"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch #0 start\n","Epoch #0 end\n","Epoch #1 start\n","Epoch #1 end\n","Epoch #2 start\n","Epoch #2 end\n","Epoch #3 start\n","Epoch #3 end\n","Epoch #4 start\n","Epoch #4 end\n","Epoch #5 start\n","Epoch #5 end\n","Epoch #6 start\n","Epoch #6 end\n","Epoch #7 start\n","Epoch #7 end\n","Epoch #8 start\n","Epoch #8 end\n","Epoch #9 start\n","Epoch #9 end\n","Epoch #10 start\n","Epoch #10 end\n","Epoch #11 start\n","Epoch #11 end\n","Epoch #12 start\n","Epoch #12 end\n","Epoch #13 start\n","Epoch #13 end\n","Epoch #14 start\n","Epoch #14 end\n","Epoch #15 start\n","Epoch #15 end\n","Epoch #16 start\n","Epoch #16 end\n","Epoch #17 start\n","Epoch #17 end\n","Epoch #18 start\n","Epoch #18 end\n","Epoch #19 start\n","Epoch #19 end\n","Epoch #20 start\n","Epoch #20 end\n","Epoch #21 start\n","Epoch #21 end\n","Epoch #22 start\n","Epoch #22 end\n","Epoch #23 start\n","Epoch #23 end\n","Epoch #24 start\n","Epoch #24 end\n","Epoch #25 start\n","Epoch #25 end\n","Epoch #26 start\n","Epoch #26 end\n","Epoch #27 start\n","Epoch #27 end\n","Epoch #28 start\n","Epoch #28 end\n","Epoch #29 start\n","Epoch #29 end\n","Epoch #30 start\n","Epoch #30 end\n","Epoch #31 start\n","Epoch #31 end\n","Epoch #32 start\n","Epoch #32 end\n","Epoch #33 start\n","Epoch #33 end\n","Epoch #34 start\n","Epoch #34 end\n","Epoch #35 start\n","Epoch #35 end\n","Epoch #36 start\n","Epoch #36 end\n","Epoch #37 start\n","Epoch #37 end\n","Epoch #38 start\n","Epoch #38 end\n","Epoch #39 start\n","Epoch #39 end\n","Epoch #40 start\n","Epoch #40 end\n","Epoch #41 start\n","Epoch #41 end\n","Epoch #42 start\n","Epoch #42 end\n","Epoch #43 start\n","Epoch #43 end\n","Epoch #44 start\n","Epoch #44 end\n","Epoch #45 start\n","Epoch #45 end\n","Epoch #46 start\n","Epoch #46 end\n","Epoch #47 start\n","Epoch #47 end\n","Epoch #48 start\n","Epoch #48 end\n","Epoch #49 start\n","Epoch #49 end\n","Epoch #50 start\n","Epoch #50 end\n","Epoch #51 start\n","Epoch #51 end\n","Epoch #52 start\n","Epoch #52 end\n","Epoch #53 start\n","Epoch #53 end\n","Epoch #54 start\n","Epoch #54 end\n","Epoch #55 start\n","Epoch #55 end\n","Epoch #56 start\n","Epoch #56 end\n","Epoch #57 start\n","Epoch #57 end\n","Epoch #58 start\n","Epoch #58 end\n","Epoch #59 start\n","Epoch #59 end\n","Epoch #60 start\n","Epoch #60 end\n","Epoch #61 start\n","Epoch #61 end\n","Epoch #62 start\n","Epoch #62 end\n","Epoch #63 start\n","Epoch #63 end\n","Epoch #64 start\n","Epoch #64 end\n","Epoch #65 start\n","Epoch #65 end\n","Epoch #66 start\n","Epoch #66 end\n","Epoch #67 start\n","Epoch #67 end\n","Epoch #68 start\n","Epoch #68 end\n","Epoch #69 start\n","Epoch #69 end\n","Epoch #70 start\n","Epoch #70 end\n","Epoch #71 start\n","Epoch #71 end\n","Epoch #72 start\n","Epoch #72 end\n","Epoch #73 start\n","Epoch #73 end\n","Epoch #74 start\n","Epoch #74 end\n","Epoch #75 start\n","Epoch #75 end\n","Epoch #76 start\n","Epoch #76 end\n","Epoch #77 start\n","Epoch #77 end\n","Epoch #78 start\n","Epoch #78 end\n","Epoch #79 start\n","Epoch #79 end\n","Epoch #80 start\n","Epoch #80 end\n","Epoch #81 start\n","Epoch #81 end\n","Epoch #82 start\n","Epoch #82 end\n","Epoch #83 start\n","Epoch #83 end\n","Epoch #84 start\n","Epoch #84 end\n","Epoch #85 start\n","Epoch #85 end\n","Epoch #86 start\n","Epoch #86 end\n","Epoch #87 start\n","Epoch #87 end\n","Epoch #88 start\n","Epoch #88 end\n","Epoch #89 start\n","Epoch #89 end\n","Epoch #90 start\n","Epoch #90 end\n","Epoch #91 start\n","Epoch #91 end\n","Epoch #92 start\n","Epoch #92 end\n","Epoch #93 start\n","Epoch #93 end\n","Epoch #94 start\n","Epoch #94 end\n","Epoch #95 start\n","Epoch #95 end\n","Epoch #96 start\n","Epoch #96 end\n","Epoch #97 start\n","Epoch #97 end\n","Epoch #98 start\n","Epoch #98 end\n","Epoch #99 start\n","Epoch #99 end\n","Epoch #100 start\n","Epoch #100 end\n","Epoch #101 start\n","Epoch #101 end\n","Epoch #102 start\n","Epoch #102 end\n","Epoch #103 start\n","Epoch #103 end\n","Epoch #104 start\n","Epoch #104 end\n","Epoch #105 start\n","Epoch #105 end\n","Epoch #106 start\n","Epoch #106 end\n","Epoch #107 start\n","Epoch #107 end\n","Epoch #108 start\n","Epoch #108 end\n","Epoch #109 start\n","Epoch #109 end\n","Epoch #110 start\n","Epoch #110 end\n","Epoch #111 start\n","Epoch #111 end\n","Epoch #112 start\n","Epoch #112 end\n","Epoch #113 start\n","Epoch #113 end\n","Epoch #114 start\n","Epoch #114 end\n","Epoch #115 start\n","Epoch #115 end\n","Epoch #116 start\n","Epoch #116 end\n","Epoch #117 start\n","Epoch #117 end\n","Epoch #118 start\n","Epoch #118 end\n","Epoch #119 start\n","Epoch #119 end\n","Epoch #120 start\n","Epoch #120 end\n","Epoch #121 start\n","Epoch #121 end\n","Epoch #122 start\n","Epoch #122 end\n","Epoch #123 start\n","Epoch #123 end\n","Epoch #124 start\n","Epoch #124 end\n","Epoch #125 start\n","Epoch #125 end\n","Epoch #126 start\n","Epoch #126 end\n","Epoch #127 start\n","Epoch #127 end\n","Epoch #128 start\n","Epoch #128 end\n","Epoch #129 start\n","Epoch #129 end\n","Epoch #130 start\n","Epoch #130 end\n","Epoch #131 start\n","Epoch #131 end\n","Epoch #132 start\n","Epoch #132 end\n","Epoch #133 start\n","Epoch #133 end\n","Epoch #134 start\n","Epoch #134 end\n","Epoch #135 start\n","Epoch #135 end\n","Epoch #136 start\n","Epoch #136 end\n","Epoch #137 start\n","Epoch #137 end\n","Epoch #138 start\n","Epoch #138 end\n","Epoch #139 start\n","Epoch #139 end\n","Epoch #140 start\n","Epoch #140 end\n","Epoch #141 start\n","Epoch #141 end\n","Epoch #142 start\n","Epoch #142 end\n","Epoch #143 start\n","Epoch #143 end\n","Epoch #144 start\n","Epoch #144 end\n","Epoch #145 start\n","Epoch #145 end\n","Epoch #146 start\n","Epoch #146 end\n","Epoch #147 start\n","Epoch #147 end\n","Epoch #148 start\n","Epoch #148 end\n","Epoch #149 start\n","Epoch #149 end\n","Epoch #150 start\n","Epoch #150 end\n","Epoch #151 start\n","Epoch #151 end\n","Epoch #152 start\n","Epoch #152 end\n","Epoch #153 start\n","Epoch #153 end\n","Epoch #154 start\n","Epoch #154 end\n","Epoch #155 start\n","Epoch #155 end\n","Epoch #156 start\n","Epoch #156 end\n","Epoch #157 start\n","Epoch #157 end\n","Epoch #158 start\n","Epoch #158 end\n","Epoch #159 start\n","Epoch #159 end\n","Epoch #160 start\n","Epoch #160 end\n","Epoch #161 start\n","Epoch #161 end\n","Epoch #162 start\n","Epoch #162 end\n","Epoch #163 start\n","Epoch #163 end\n","Epoch #164 start\n","Epoch #164 end\n","Epoch #165 start\n","Epoch #165 end\n","Epoch #166 start\n","Epoch #166 end\n","Epoch #167 start\n","Epoch #167 end\n","Epoch #168 start\n","Epoch #168 end\n","Epoch #169 start\n","Epoch #169 end\n","Epoch #170 start\n","Epoch #170 end\n","Epoch #171 start\n","Epoch #171 end\n","Epoch #172 start\n","Epoch #172 end\n","Epoch #173 start\n","Epoch #173 end\n","Epoch #174 start\n","Epoch #174 end\n","Epoch #175 start\n","Epoch #175 end\n","Epoch #176 start\n","Epoch #176 end\n","Epoch #177 start\n","Epoch #177 end\n","Epoch #178 start\n","Epoch #178 end\n","Epoch #179 start\n","Epoch #179 end\n","Epoch #180 start\n","Epoch #180 end\n","Epoch #181 start\n","Epoch #181 end\n","Epoch #182 start\n","Epoch #182 end\n","Epoch #183 start\n","Epoch #183 end\n","Epoch #184 start\n","Epoch #184 end\n","Epoch #185 start\n","Epoch #185 end\n","Epoch #186 start\n","Epoch #186 end\n","Epoch #187 start\n","Epoch #187 end\n","Epoch #188 start\n","Epoch #188 end\n","Epoch #189 start\n","Epoch #189 end\n","Epoch #190 start\n","Epoch #190 end\n","Epoch #191 start\n","Epoch #191 end\n","Epoch #192 start\n","Epoch #192 end\n","Epoch #193 start\n","Epoch #193 end\n","Epoch #194 start\n","Epoch #194 end\n","Epoch #195 start\n","Epoch #195 end\n","Epoch #196 start\n","Epoch #196 end\n","Epoch #197 start\n","Epoch #197 end\n","Epoch #198 start\n","Epoch #198 end\n","Epoch #199 start\n","Epoch #199 end\n"]}],"source":["#train model - final******** with 200 epochs\n","epoch_logger = EpochLogger()\n","## Train doc2vec model\n","model1 = Doc2Vec(tagged_data, vector_size=20, window=2, min_count=1, workers=4, epochs = 200, callbacks=[epoch_logger])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XpC6PuLNXdPf"},"outputs":[],"source":["# Save trained doc2vec model\n","model1.save(\"models/my_doc2vec.model\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ran3nux7XdPh"},"outputs":[],"source":["## Load saved doc2vec model\n","model1= Doc2Vec.load(\"models/my_doc2vec.model\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oiCl-cLuXdPi","outputId":"17a5cc35-f685-4b30-9cff-25919c0f2b21","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1666505563601,"user_tz":-480,"elapsed":303,"user":{"displayName":"Qi Li","userId":"16904504519531243661"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["21996"]},"metadata":{},"execution_count":27}],"source":["#confirm length (should be 38941)\n","len(tokenized_doc)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ovx4dIwEXdPj"},"outputs":[],"source":["## Get vector value\n","vec = np.empty([21996,20])\n","\n","for k,i in enumerate(tokenized_doc):\n","    #print(i)\n","    vector = model1.infer_vector(i)\n","    vec[k] = vector\n","\n","# reshape into 2D\n","new_arr = np.reshape(vec,(-1,20))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jIItt5QqXdPk"},"outputs":[],"source":["rng = range(1, 21)\n","vec_df = pd.DataFrame(new_arr, columns=['vec_' + str(i) for i in rng])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CaoZvZzlXdPk","outputId":"2983c66c-039b-45e9-c521-e65961ea7336","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1666507396224,"user_tz":-480,"elapsed":6,"user":{"displayName":"Qi Li","userId":"16904504519531243661"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 21996 entries, 0 to 21995\n","Data columns (total 20 columns):\n"," #   Column  Non-Null Count  Dtype  \n","---  ------  --------------  -----  \n"," 0   vec_1   21996 non-null  float64\n"," 1   vec_2   21996 non-null  float64\n"," 2   vec_3   21996 non-null  float64\n"," 3   vec_4   21996 non-null  float64\n"," 4   vec_5   21996 non-null  float64\n"," 5   vec_6   21996 non-null  float64\n"," 6   vec_7   21996 non-null  float64\n"," 7   vec_8   21996 non-null  float64\n"," 8   vec_9   21996 non-null  float64\n"," 9   vec_10  21996 non-null  float64\n"," 10  vec_11  21996 non-null  float64\n"," 11  vec_12  21996 non-null  float64\n"," 12  vec_13  21996 non-null  float64\n"," 13  vec_14  21996 non-null  float64\n"," 14  vec_15  21996 non-null  float64\n"," 15  vec_16  21996 non-null  float64\n"," 16  vec_17  21996 non-null  float64\n"," 17  vec_18  21996 non-null  float64\n"," 18  vec_19  21996 non-null  float64\n"," 19  vec_20  21996 non-null  float64\n","dtypes: float64(20)\n","memory usage: 3.4 MB\n"]}],"source":["vec_df.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NpExZxQ2XdPl"},"outputs":[],"source":["con_job_1 = pd.concat([job, vec_df], axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RS6J8edsXdPm"},"outputs":[],"source":["#saving final csv with additional vectors to match with resume. \n","con_job_1.to_csv('data/vectoe_job_20.csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZP1cszpvXdPm"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}